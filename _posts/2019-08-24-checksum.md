---
layout: post
date: 2019-08-27
title: Variational Inference of Normalizing Flows (Rezende & Shakir, 2015)
tags: [paper_summary]
mathjax: true
---


[Original paper link](http://proceedings.mlr.press/v37/rezende15.pdf)

## Normalizing Flows

**Key idea**: Assume a simple probability distribution, take a sample from it and then ___transform___ that sample. This is equivalent to change of variables in probability distributions and, if the transformation meets some mild conditions, can result in a very complex pdf of the transformed variable. The formalism of normalizing flows now gives us a systematic way of specifying the approximate posterior distributions $q(z\vert x)$ required for variational inference.

Example: If $f$ is monotonically increasing or monotonically decreasing function, such that $y = f(x)$, $x \sim p_{X}$, then we have:
\\[ p_{Y}(y)= \frac{d}{dy}\mathbb{P}(Y\leq y)= \frac{d}{dy}\mathbb{P}(f(X)\leq y)=\frac{d}{dy}\mathbb{P}(X\leq f^{-1}(y))=p_{X}(f^{-1}(y))\frac{df^{-1}(y)}{dy}=p_{X}(x)\frac{df^{-1}(y)}{dy},\\]
\\[ p_{Y}(y)= \frac{d}{dy}\mathbb{P}(Y\leq y)= \frac{d}{dy}\mathbb{P}(f(X)\leq y)=\frac{d}{dy}\mathbb{P}(X\geq f^{-1}(y))=-p_{X}(f^{-1}(y))\frac{df^{-1}(y)}{dy}=-p_{X}(x)\frac{df^{-1}(y)}{dy},\\]
respectively.

Similarly for multivariate invertible mappings $f:\mathbb{R}^{m}\mapsto \mathbb{R}^{m}$ and $X\sim p_{X}$, $Y=f(X)$, we get:

\\[\boxed{ p_{Y}(y)=p_{X}(x)\left\lvert \operatorname{det}\frac{df^{-1}(y)}{dy}\right\rvert =p_{X}(x)\left\lvert \operatorname{det}\frac{df(x)}{dy}\right\rvert^{-1} },\qquad complexity \rightarrow O(m^{3})\\]
where the last equality exploits $[ \mathrm{det}(A^{-1}) =\mathrm{det}(A)^{-1} ]$ and the [property of jacobian of inverse functions](https://en.wikipedia.org/wiki/Inverse_function_theorem) (PS: invertibility of $f(\cdot)$ validates the use of this property).

NFs are typically used to parametrise the approximate posterior $q(z\vert x)$ but can also be applied for the likelihood function. We can apply a series of mappings  $f_{k},~ k= \[ 1,\dots,K \]$ and obtain a normalizing flow:

$$ \mathbf{z}_K = f_K \circ \dots \circ f_1 (\mathbf{z}_0), \quad \mathbf{z}_0 \sim q_0(\mathbf{z}_0), $$  

$$ \mathbf{z}_K \sim q_K(\mathbf{z}_K) = q_0(\mathbf{z}_0) \prod_{k=1}^K
  \left|
    \mathrm{det} \frac{
      \partial f_k
    }{
      \partial \mathbf{z}_{k-1}\
    }
  \right| ^{-1}, \quad or $$

  $$ \ln q_K (\mathbf{z}_K) = \ln q_0(\mathbf{z}_0) - \sum_{k=1}^{K} \ln \mathrm{det} \left|
     \frac{
      \partial f_k
    }{
      \partial \mathbf{z}_{k-1}\
    }
  \right|. $$ 

This series of transformations can transform a simple probability distribution (e.g. Gaussian) into a complicated multi-modal one. To be of practical use, however, we can consider only transformations whose determinants of Jacobians are easy to compute. The original paper considered two simple family of transformations, named planar and radial flows.

## Planar Flow
\\[ f(\mathbf{z}) = \mathbf{z} + \mathbf{u} h(\mathbf{w}^{\top} \mathbf{z} + b) \\]
with $\mathbf{U}, \mathbf{W}\in \mathbb{R}^{d}$ and $b\in \mathbb{R}$ and $h$ an elemnet-wise non-linearity. Let $\psi (\mathbf{z}) = h' (\mathbf{w}^T \mathbf{z} + b) \mathbf{w}$. Then the determinant can be easily computed as

\\[ \left| \mathrm{det} \frac{\partial f}{\partial \mathbf{z}} \right| =
  \left| 1 + \mathbf{u}^{\top} \psi( \mathbf{z} ) \right| = \left| 1 + \mathbf{u}^{\top} h' (\mathbf{w}^T \mathbf{z} + b) \mathbf{w} \right| .  \\]
Since $0\leq h' \leq 1$ for $ h(x) = \tanh (x) $, we require $ \mathbf{u}^{\top}\mathbf{w} \geq -1$ for invertibility of such flows. We can think of planar flows as slicing the $\mathbf{z}$-space with straight lines (or hyperplanes), where each line contracts or expands the space around it, see figure 1 (in paper).

## Radial Flow
\\[  f(\mathbf{z}) = \mathbf{z} + \beta h(\alpha, r)(\mathbf{z} - \mathbf{z}_0),\\]

with $$r = \Vert\mathbf{z} - \mathbf{z}_0 \Vert_2 $$, $$h(\alpha, r) = \frac{1}{\alpha + r}$$ and parameters $$\mathbf{z}_0 \in \mathbb{R}^d, \alpha \in \mathbb{R}_+$$ and $$\beta \in \mathbb{R}$$.

Similarly to planar flows, radial flows introduce spheres in the $z$-space, which either contract or expand the space inside the sphere, see figure 1 (in paper).

### Density estimation (Generative modelling)
$p_X:$ data distribution, $p_Y:$ prior ob latent variable, $p_{f^{-1}(Y)}:$ push-forward density of $f^{-1}(Y)$, i.e the generative model

$$\begin{align*}
 D_{KL}(p_X \Vert p_{f^{-1}(Y)}) & = \mathbb{E}_{x\sim p_{X}}\left[ \log p_X (x) - \log p_{f^{-1}(Y)} (x) \right] \\ 
                                & = \mathbb{E}_{x\sim p_{X}}\left[ \log p_X (x) - \log p_{X} (x) \right] \\
                                & = \mathbb{E}_{x\sim p_{X}}\left[ \log p_X (x) - \log p_{Y} (f(x))\left| \mathrm{det} \frac{\partial f(x)}{\partial x} \right|\right]\\
                                & = \mathbb{E}_{x\sim p_{X}}\left[ \log p_X (x) - \log p_{Y} (f(x)) - \log \left| \mathrm{det} \frac{\partial f(x)}{\partial x} \right|\right]
\end{align*} $$
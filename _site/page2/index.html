<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel="icon" type="image/icon" href="favicon.ico">


<title>Home</title>


<script src="https://storage.googleapis.com/montco-stats/javascript/vis-4.17.0/dist/vis.js" type="text/javascript"></script>
<link href="https://storage.googleapis.com/montco-stats/javascript/vis-4.17.0/dist/vis-network.min.css" rel="stylesheet" type="text/css" />

<link rel="stylesheet" href="http://localhost:4000/css/syntax.css">
<link rel="stylesheet" href="http://localhost:4000/css/main.css">
</head>
<body>


<header>
<div id="nav_container">
<nav>

  <ul>
  <h1><a href="">Research Notes</a></h1>
    
      
      

      <li class="">
        <a class="" href="http://localhost:4000/about/">About</a>
      </li>
    
      
      

      <li class="">
        <a class="" href="http://localhost:4000/tutorials/">Tutorials</a>
      </li>
    
      
      

      <li class="">
        <a class="" href="http://localhost:4000/paper_summary/">Paper Summaries</a>
      </li>
    
      
      

      <li class="">
        <a class="" href="http://localhost:4000/distill/">Distills</a>
      </li>
    
      
      

      <li class="">
        <a class="" href="http://localhost:4000/tags/">Archives</a>
      </li>
    
  </ul>

</nav>
</div>
</header>

<section id="main">
	  
      <article>
      <div class="heading"><a href="/post/optimal-stopping-problem/">Optimal Stopping Problem</a></div>
      <p class="meta"><a class="permalink" href="/post/optimal-stopping-problem/">&#9679;</a> 24 Aug 2019</p>
      <div>
        <p>There are a lot of everyday situations where people make decisions one after the other, and what is decided earlier affects the choices later on. Most people probably go by some gut feeling about when it’s time to stop and select the next best option and settle down.</p>

<p>In this article we will examine the “Optimal Stopping Problem,” a mathematical puzzle that can manifest in many different real world examples. For instance:</p>

<ul>
  <li>When should a hiring manager stop interviewing people for a new job position? <br />
This is the classical “secretary problem” within the field of study of mathematics: probability-optimization. This problem in it’s simplest form has following features:
    <ul>
      <li>There is one secretarial position available.</li>
      <li>The number of applicants is $n$.</li>
      <li>The applicants are interviewed sequentially in random order, each order being equally likely.</li>
      <li>After each interview the hiring manager must decide to reject or hire the applicant.</li>
      <li>An applicant once rejected cannot later be recalled.</li>
      <li>Once the hiring manager decides to hire an applicant his/her search is over and there is no need to interview any more candidates.<br />
This basic problem has a remarkably simple solution and was outlined in the basic paper by  Gilbert and Mosteller ( 1966 ), with elegant derivations and extensions in a number of important directions.</li>
    </ul>
  </li>
  <li>
    <p>We have a house and we wish to sell it. Each day we get a new offer for the house, which could be higher or lower than the previous offer; however, each day the house is on the market we must pay for advertising. We wish to maximise the amount you earn by choosing a stopping rule. When should we stop looking at potential buyers and finally settle the deal?</p>
  </li>
  <li>
    <p>At some point in a lot of peoples lives, we wonder when we should stop dating and finally settle down with the right partner. Most people probably go by some gut feeling about when it’s time to stop. Editor’s Note: Of course, for mathematicians this is a purely theoretical example.</p>
  </li>
  <li>Suppose we are a doctor and patients arrive sequentially at our clinic and must be treated immediately by one of the treatments. It is assumed that response from treatment is immediate so that the effectiveness of the treatment that the present patient receives is known before the next patient is treated. It is not known precisely which one of the treatments is best, but we must decide which treatment to give each patient, keeping in mind that our goal is to cure as many patients as possible. This may require us to give a patient a treatment which is not the one that looks best at the present time in order to gain information that may be of use to future patients. When should we <strong>stop evaluating</strong> more treatments and finally select the best one?</li>
</ul>

<p>There are many different solutions to the problems listed above, as the strategy we choose will depend on our objective. Do we want to ensure that the option we select is better than average? What if we just want to be sure that we do not pick the worst option? In this article our goal will be to “<strong>minimize the risk</strong>” of missing the best option. In other words, we want to “maximize the chances” (i.e. probability) of selecting the best option.</p>

<h3 id="the-prelude">The Prelude</h3>

<p>The general form of our strategy will be to “gather information” when we are presented with our first options. We know that we will not choose any of these; however, we will examine them in order to know “how good” we should expect our options to be. After a certain point, once we are done gathering information, we will choose the first option that was better than all the ones we have seen before. After some thought, we can see that this strategy makes some intuitive sense. We don’t want to choose an option too early since there would be a high likelihood a better option would come later. But when should we stop gathering information? While we don’t want to choose an option too early, we certainly don’t want to gather information for too long and risk the best option passing us by.</p>

<p>This type of problem is called the “<strong>Optimal Stopping Problem</strong>”, which mathematicians and computer scientists have researched for many years.</p>

<h3 id="a-real-life-example">A Real-life Example</h3>

<p>Suppose we want to sell our house. We have a pool of n potential buyers (we number them from $1$ to $n$), who we meet one after the other. After a potential buyer has made their offer, we must decline or accept their offer. If we decide to accept their offer, we can no longer sell the house to anyone else and if we reject an offer the buyer will take their business elsewhere, and we will not be able to change our minds later on. For simplicity’s sake, we will assume there is no advertising cost (i.e. we do not have to pay to keep our house on the market).</p>

<p>Among our pool of $n$ people, there’s at least one who gives us the highest value for our property. We will call that person  $m$  (where  $m$  ranges from  $1$  to  $n$) – it’s who we’d ideally want to end up making deal with.</p>

<p>Our strategy is to discuss the deal with  $m-1$  of the $n$ people and then settle with the next best person who is better. (The reason for doing the calculations with  $m-1$  is that  m is the minimum number of potential buyers that we will encounter; there are  $m-1$  who give us the data we need before we start searching, and the $m^{th}$ is the first one who can be accepted.)</p>

<p>Given a pool of $n$ potential buyers, let $P(m; n)$ represent the probability that we will choose the best offer if we use the strategy discussed earlier. I.e. If there are $n$ buyers and we “gather information” during the first $m-1$ offers and pick the first offer that is better than the current best, the probability that we will select the best possible offer is $P(m; n)$.</p>

<p>Notice immediately that $P(1; n) = \dfrac{1}{n}$ and $P(n; n) = \dfrac{1}{n}$. These two cases essentially give no choice, meaning, it is just like the probability of picking one person at random out of total number of people ($n$) and hence the probability is $\dfrac{1}{n}$. But interesting things happen ‘<strong><em>in between</em></strong>’ these two extremes. As we see more people , we already have a notion of the “best so far,” and the next person we see that beats the current “best so far” is more likely to be the best person in the group for us. Unfortunately, it works the other way around as well. As we continue to see more people, the likelihood of having already passed the best so far increases, thereby decreasing our chances at finding the optimal person.</p>

<p>We want to find the optimal place to stop – a sort of middle ground that maximizes our chances of choosing the optimal person.</p>

<p>To do this, we want to maximize $P(m; n)$. In the process of doing this, we want to make sure our solution generalizes. A good way to generalize is to find the right ratio $\dfrac{m}{n}$, the percentage of our population that we should analyze before making a decision.</p>

<h4 id="mathematical-formalism">Mathematical Formalism</h4>
<p>Our first step here is to get an equation for $P(m; n)$.</p>

<p>Let’s say we have collected information about $m - 1$ potential buyers and now are looking at the $k^{th}$ person in the sequence, where  $m-1 \leq k \leq n$.</p>

<p>Now let’s break down some things that are going on here:</p>
<ul>
  <li>We know that this  $k^{th}$  person has a $\dfrac{1}{n}$ probability of being the best buyer.</li>
  <li>We also know that in order to be considering the $k^{th}$ buyer in this sequence, the highest ranking person thus far must be in the group of $m - 1$ people out of the $k - 1$ people we had previously inspected and rejected (otherwise we would have stopped at someone before the $k^{th}$ person).</li>
</ul>

<p>And the probability of the highest ranked person thus far being in that group of $m - 1$ people out of the $k - 1$ people inspected is:
\[ \dfrac{m - 1}{k - 1}. \]</p>

<p>And therefore, the overall probability of finding the best potential partner this time is:
\[ (\dfrac{m - 1}{k - 1}).(\dfrac{1}{n}) = \dfrac{m - 1}{n(k - 1)}\]</p>

<p>Note: In the following section we will use summation notation ($ \sum $ symbol), which works as follows: Suppose we have a sequence of numbers $x_1, x_2, …, x_n$, then, by definition, $\sum_{i=1}^{n} x_i = x_1 + x_2 + x_3 + … + x_n$. Thus $\sum_{i=1}^{n} 1 = n$ and $\sum_{i=1}^{3} x_i = x_1 + x_2 + x_3$. We use this notation because it is shorter than writing out each term in the sum.</p>

<p>Now to determine $ P(m; n) $, we must remember that $ k $ can take on any value from $ m $ to $ n $. As a consequence, we must sum these probabilities for any value of $ k $ (note the range of $ k $ above). A compact way to express this is as follows:
\[P(m; n) =\sum_{k=m}^{n} \dfrac{m-1}{n(k - 1)}= \dfrac{m-1}{n}\sum_{k=m}^{n}\dfrac{1}{k-1}. \tag{1} \label{1}\]</p>

<p>At this point, it is possible to determine the maximum value using methods of optimization one learns in calculus, but this can get nasty pretty quickly. We will lay out a more elegant (albeit more mathematically involved) approach in the following section.</p>

<h4 id="to-get-more-technical">To Get More Technical</h4>
<p>Given a number $n$, we want to maximize the value of $P(m;n)$. Hence, the optimal value for $ m $ will be such that:
       \[P(m - 1; n) &lt; P(m; n) \text{ and } P(m + 1; n) &lt; P(m;n) \tag{2} \label{2}\]</p>

<p>Author’s Note: If you want to be very pedantic, you could ask what happens if there are two “best” values of $ m $, with one of those strict inequality signs replaced by a partial inequality. It turns out that the only time when equality is possible is when $ n=2 $, which is not very interesting anyway.</p>

<p>Let’s break this down part by part. From the first inequality in (\ref{2}) and using (\ref{1}):
\[P(m - 1; n) &lt; P (m; n)\]</p>

<p>\[\dfrac{m-2}{n}\sum_{k=m-1}^{n} \dfrac{1}{k - 1}&lt;\dfrac{m-1}{n} \sum_{k=m}^{n}\dfrac{1}{k-1}\]</p>

<p>\[(m-2)\sum_{k=m-1}^{n} \dfrac{1}{k - 1}&lt;(m-1) \sum_{k=m}^{n}\dfrac{1}{k-1}.\]</p>

<p>Rewriting the left hand side:</p>

<p>\[(m-2)(\dfrac{1}{m-2})+\sum_{k=m}^{n} \dfrac{1}{k - 1}&lt;(m-1) \sum_{k=m}^{n}\dfrac{1}{k-1}.\]</p>

<p>After algebraic simplification, we get:
    \[1&lt;\sum_{k=m}^{n}\dfrac{1}{k-1}\tag{3} \label{3}\]</p>

<p>Let’s now do the same thing for the other inequality from (\ref{2}):</p>

<p>\[P (m; n) &gt; P (m + 1; n)\]</p>

<p>\[(m-1)\sum_{k=m}^{n}\dfrac{1}{k-1}&gt;m\sum_{k=m+1}^{n}\dfrac{1}{k-1}\]</p>

<p>Performing a similar calculations to what we did with the last inequality, we get:</p>

<p>\[(m-1)(\dfrac{1}{m-1}+\sum_{k=m+1}^{n}\dfrac{1}{k-1})&gt;m\sum_{k=m+1}^{n}\dfrac{1}{k-1}\]</p>

<p>\[(1+(m-1)\sum_{k=m+1}^{n}\dfrac{1}{k-1})&gt;m\sum_{k=m+1}^{n}\dfrac{1}{k-1}\]</p>

<p>\[1&gt;\sum_{k=m+1}^{n}\dfrac{1}{k-1}\tag{4}\label{4}\]</p>

<p>Let’s remember that our goal here is to find an appropriate approximation for the ratio $ \dfrac{m}{n} $ for the best $ m  $.</p>

<p>One fact that is going to help us immensely in this calculation is the approximation of the partial sum of a harmonic series. Mathematically, the approximation is:</p>

<p>\[\sum_{k=1}^{x}\dfrac{1}{k}\approx\ln(x)+c \]</p>

<p>where $ c $ is the Euler-Mascheroni constant.</p>

<p>Now this approximation greatly helps us simplify inequalities (\ref{3}) and (\ref{4}).</p>

<p>Using this approximation for (\ref{3}), we derive the following:</p>

<p>\[1&lt;\sum_{k=m}^{n}\dfrac{1}{k-1}=\sum_{k=m-1}^{n-1}\dfrac{1}{k}=\sum_{k=1}^{n-1}\dfrac{1}{k}-\sum_{k=1}^{m-2}\dfrac{1}{k}\approx\ln(\dfrac{n-1}{m-2})\]</p>

<p>Similarly, for (\ref{4}), we obtain:</p>

<p>\[1&gt;\sum_{k=m+1}^{n}\dfrac{1}{k-1}=\sum_{k=m}^{n-1}\dfrac{1}{k}=\sum_{k=1}^{n-1}\dfrac{1}{k}-\sum_{k=1}^{m-1}\dfrac{1}{k}\approx\ln(\dfrac{n-1}{m-1})\]</p>

<p>Alright, almost done! Notice that we can make another approximation of these results for large $ n $.</p>

<p>For sufficiently large $ n $, the constants in our expressions will make negligible difference in our final result, allowing us to make the following claim:</p>

<p>\[1\approx\ln(\dfrac{n}{m})\]</p>

<p>Now, using the properties of natural logarithm, value of $e$ and then taking it’s inverse, we get:</p>

<p>\[\boxed{(\dfrac{m}{n})\approx(\dfrac{1}{e})\approx 0.37}\]</p>

<p><em>Q.E.D.</em></p>

<p>This result was proven through a lot of (good) approximations, but other more rigorous methods including those used in optimization come to the same result.</p>

<p>So here we have it! A proof of why you should keep $37\%$ on your mind when it comes to matters of making choices.</p>

        </div>
             
	
    	<span class="label label-default"><a href="/tags#distill-ref" title="View posts tagged with &quot;distill&quot;">distill</a></span>
    


     </article>
     <hr>
  
      <article>
      <div class="heading"><a href="/post/inf_prob_models/">Inference in probabilistic models</a></div>
      <p class="meta"><a class="permalink" href="/post/inf_prob_models/">&#9679;</a> 08 Aug 2019</p>
      <div>
        <p>Statistical Machine Learning algorithms try to learn the structure of data by fitting a parametric distribution $p(x;θ)$ to it. Given a dataset, if we can represent it with a distribution, we can:</p>

<ol>
  <li>Generate new data “for free” by sampling from the learned distribution in silico; no need to run the true generative process for the data. This is a useful tool if the data is expensive to generate, i.e. a real-world experiment that takes a long time to run. Sampling is also used to construct estimators of high-dimensional integrals over spaces.</li>
  <li>Evaluate the likelihood of data observed at test time (this can be used for rejection sampling or to score how good our model is).</li>
  <li>Find the conditional relationship between variables. For example, learning the distribution $p(x_2\vert x_1)$ allows us to build discriminative classification or regression models.</li>
  <li>Score our algorithm by using complexity measures like entropy, mutual information, and moments of the distribution.</li>
</ol>

<p><strong>Inference</strong>: $x\sim p_{X}$, $z=f(x)$.<br />
<strong>Generation</strong>: $z\sim p_{Z}$, $x=f^{-1}(z)$</p>

<p>How can we use a model $p(\mathbf{x}, \mathbf{z})$ to analyze some data $\mathbf{x}$? In other words, what hidden structure of $\mathbf{z}$ explains the data? We seek to infer this hidden structure using the model.</p>

<p>One method of inference leverages Bayes’ rule to define the posterior
\[p(\mathbf{z} \mid \mathbf{x}) = \frac{p(\mathbf{x}, \mathbf{z})}{\int_{z} p(\mathbf{x}, \mathbf{z}) \text{d}\mathbf{z}}.\]
​​ 
The posterior is the distribution of the latent variables $\mathbf{z}$, conditioned on some (observed) data $\mathbf{x}$. Drawing analogy to representation learning, it is a probabilistic description of the data’s hidden representation. Often this distribution is unknown and difficult to compute due to intractable denominator (which has to be computed over all comfiguration of states). Hence, we go for approximations.</p>

<p>$2$ methods exist: Sampling methods a.k.a. Monte-Carlo methods and Variational inference.</p>

<p><strong>Sampling methods</strong> involves drawing random samples from an unknown true distribution. Some methods are Importance sampling, Rejection sampling, Metropolis-hastings method and Gibbs sampling. The last two mthods falls under category of MCMC methods.</p>

<p><strong>Variational methods</strong> involves approximating the unknown true distribution $p(\mathbf{x})$ with a simpler known distribution $q(\mathbf{x};\theta)$ parametrized by $\theta$. Basically we minimize the divergence between these distributions over $\theta$. To approximate $p(\mathbf{x})$, <em>variational lower bound</em> is the key. We then maximize this VB to approximate $q$ to $p$. Its connections with deeplearning are beautifully established in paper - <a href="https://arxiv.org/abs/1312.6114">Auto-encoding Variational Bayes (Kingma &amp; Welling, 2014)</a>.</p>

<p>More on these methods could be read in the excellent book by David Mckay - `Information theory, Inference and Learning Algorithms’ and from blogs <a href="https://medium.com/neuralspace/inference-in-probabilistic-models-monte-carlo-and-deterministic-methods-eae8800ee095">1</a>, <a href="http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html">2</a>.</p>

<hr />

<h3 id="example-use-of-variational-inference-to-obtain-lower-bound-on-the-marginal-likelihood">Example: Use of Variational Inference to obtain lower-bound on the marginal likelihood</h3>
<p>Consider a general probabilistic model with observations $x$, latent variables $z$ over which we must integrate, and model parameters $θ$. We introduce an approximate posterior distribution for the latent variables $q_{\phi}(z\vert x)$ and follow the variational principle (Jordan et al., 1999) to obtain a bound on the marginal likelihood:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*} \log p_{θ}(x) & = \log \int p_{θ}(x\vert z)p(z)dz \\ 
                              & = \log \int \frac{q_{\phi}(z\vert x)}{q_{\phi}(z\vert x)} p_{θ}(x\vert z)p(z)dz \\
                              & = \log \left( \mathbb{E}_{q} \left[ \frac{p( z)}{q_{\phi}(z\vert x)} . q_{\phi}(z\vert x) p_{θ}(x\vert z) \right] \right) \\
                              & \geq \mathbb{E}_{q} \left[\log \left(\frac{p( z)}{q_{\phi}(z\vert x)} . q_{\phi}(z\vert x) p_{θ}(x\vert z)\right) \right]  \\
                              & \geq \mathbb{E}_{q} \left[\log \left(\frac{p( z)}{q_{\phi}(z\vert x)}\right) + \log\left(q_{\phi}(z\vert x) p_{θ}(x\vert z)\right) \right]  \\
                              & = -\mathbb{D}_{\mathrm{KL}} [q_{\phi}(z\vert x) \Vert p( z)] + \mathbb{E}_q [\log p(x\vert z)],
        \end{align*} %]]></script>

<p>where we have used Jensen’s inequality $ \left(f (\mathbb{E}[x]) ≤ \mathbb{E} [f(x)]\right) $. $p_θ (x\vert z)$ is a likelihood function and $p(z)$ is a prior over the latent variables. This bound is often referred to as the negative free energy $\mathcal{F}$ or as the evidence lower bound (ELBO). It consists of two terms: the first is the KL-divergence between the approximate posterior and the prior distribution (which acts as a regularizer), and the second is a reconstruction error. This bound provides a unified objective function for optimization of both the parameters $θ$ and $\phi$ of the model and variational approximation, respectively.</p>

<p>Current best practice in variational inference performs this optimization using mini-batches and stochastic gradient descent, which is what allows variational inference to be scaled to problems with very large data sets. There are two problems that must be addressed to successfully use the variational approach:</p>

<ol>
  <li>efficient computation of the derivatives of the expected log-likelihood <script type="math/tex">\nabla_{\phi} \mathbb{E}_{q_{\phi}(z)}\left[\log p_{\theta} (x\vert z)\right]</script>. This is tackled in the paper <a href="https://arxiv.org/abs/1312.6114">Auto-encoding Variational Bayes (Kingma &amp; Welling, 2014)</a></li>
  <li>choosing the richest, computationally-feasible approximate posterior distribution $q(·)$. This is tackled in the paper <a href="/post/checksum/">Variational Inference of Normalizing Flows (Rezende &amp; Shakir, 2015)</a>.</li>
</ol>

        </div>
             
	
    	<span class="label label-default"><a href="/tags#distill-ref" title="View posts tagged with &quot;distill&quot;">distill</a></span>
    


     </article>
     <hr>
  
      <article>
      <div class="heading"><a href="/post/latexsublime-workflow/">Latex+Sublime+MathJax+Jekyll workflow</a></div>
      <p class="meta"><a class="permalink" href="/post/latexsublime-workflow/">&#9679;</a> 11 May 2019</p>
      <div>
        <p>So basically to make heavy math websites faster, use the workflow as below:</p>

<ol>
  <li>Have the pre-requisites installed first i.e. latex using miktex and Sublime text 3.</li>
  <li>Make sure you have Perl also on your system.</li>
  <li>Add “latexindent.pl” package from miktex.</li>
  <li>Now set-up your sublime text as follows:
    <ul>
      <li>First things first: install ‘package control’</li>
      <li>Then add the following packages: LaTexTools, LateXYZ, Jekyll, BeautifyLatex</li>
      <li>Optionally add these packages just to make your experience better: materialtheme, side bar, advanced new file, file icon and GitGutter.</li>
    </ul>
  </li>
  <li>If needed, use Pandoc to convert tex file to html</li>
</ol>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">pandoc</span> <span class="o">-</span><span class="n">s</span> <span class="n">name_of_tex_file</span><span class="o">.</span><span class="n">tex</span> <span class="o">--</span><span class="n">mathjax</span> <span class="o">-</span><span class="n">o</span> <span class="n">name_of_ex_file</span><span class="o">.</span><span class="n">html</span> </code></pre></figure>

<p>That’s it. Your set-up is done!</p>

<p>To work faster with Sublime, learning keybindings (a.k.a keyboard shortcuts) is a must.</p>

        </div>
             
	
    	<span class="label label-default"><a href="/tags#distill-ref" title="View posts tagged with &quot;distill&quot;">distill</a></span>
    


     </article>
     <hr>
  
      <article>
      <div class="heading"><a href="/post/FactOnFuncAna/">LMI Formulation</a></div>
      <p class="meta"><a class="permalink" href="/post/FactOnFuncAna/">&#9679;</a> 01 May 2019</p>
      <div>
        <html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Arun Pandey" />
  <title>LMI formulation for Deep Learning</title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body>
<div id="header">
</div>
<h1 id="introduction">Introduction</h1>
<p>Representing the objective function in energy form: <span class="math display">\[\begin{aligned}
        \underset{w_1, w_2}{min} &amp; J = &amp; -x^\top  w_1 h_1 - \sigma(h_1)^\top  w_2 h_2.
    \end{aligned}\]</span> <span class="math inline">\( J \)</span> could be written in quadratic form as:</p>
<p><span class="math display">\[J=
    -\dfrac{1}{2}\begin{bmatrix}
        x^\top &amp; h_{1}^\top &amp; \sigma(h_1)^\top &amp; h_{2}^\top
    \end{bmatrix}
    \begin{bmatrix}
        \ast       &amp; w_{1} &amp; \ast       &amp; \ast \\
        w_{1}^\top &amp; \ast  &amp; \ast       &amp; \ast \\
        \ast       &amp; \ast  &amp; \ast       &amp; w_2  \\
        \ast       &amp; \ast  &amp; w_{2}^\top &amp; \ast \\
    \end{bmatrix}
    \begin{bmatrix}
        x \\ h_{1} \\ \sigma\left(h_1\right) \\ h_{2}
    \end{bmatrix}\]</span></p>
<p>Now, we characterizing the objective <span class="math inline">\( J \)</span> in terms of <span class="math inline">\( 1^{st}\)</span> layer using parameter <span class="math inline">\( \gamma \)</span>, the augmented objective is given by: <span class="math display">\[J \leq -\gamma x^\top w_1 h_1,\]</span></p>
<p>for some <span class="math inline">\( \gamma \gt 0 \)</span>. Using the sector <span class="math inline">\( \left[0,1\right] \)</span> non-linearity <span class="math display">\[\sigma\left(h_1 \right)^\top  \left( \sigma(h_1) - h_1 \right) \leq 0,~~~\forall h_1\]</span> and s-procedure trick, we obtain the following:</p>
<p><span class="math display">\[-(1-\gamma)x^\top w_1 h_1 - \sigma(h_1)^\top w_{2}h_{2}- \sigma\left(h_1 \right)^\top  \left( \sigma(h_1) - h_1 \right) \leq 0. ~~~\forall x, h_{1}, h_{2}\]</span> Hence, we solve the following optimization problem: <span class="math display">\[\begin{aligned}
        \underset{\gamma, w_{1}, w_{2}, h_{1_{i}}}{min} &amp; \quad -\gamma - \sum_{i}^{}x_{i}^T w_{1}h_{1_{i}} \\
        s.t.                                            &amp; -\dfrac{1}{2}\begin{bmatrix}
            x^\top &amp; h_{1}^\top &amp; \sigma(h_1)^\top &amp; h_{2}^\top
        \end{bmatrix}
        \begin{bmatrix}
            \ast                 &amp; (1-\gamma)w_{1} &amp; \ast       &amp; \ast \\
            (1-\gamma)w_{1}^\top &amp; \ast            &amp; -\mathbb{I}    &amp; \ast \\
            \ast                 &amp; -\mathbb{I}         &amp; 2\mathbb{I}    &amp; w_2  \\
            \ast                 &amp; \ast            &amp; w_{2}^\top &amp; \ast \\
        \end{bmatrix}
        \begin{bmatrix}
            x \\ h_{1} \\ \sigma\left(h_1\right) \\ h_{2}
        \end{bmatrix} \leq 0,                                                                   \\
                                                        &amp; \quad \gamma \gt 0.
    \end{aligned}\]</span> Since the first constraint is true <span class="math inline">\(\forall~ x,~ h_{1}, ~\sigma(h_{1}) ~\&amp; ~h_{2} \)</span>, we only need the matrix to be positive semi-definite. Hence, restating the above problem: <span class="math display">\[\begin{aligned}
        \underset{\gamma, w_{1}, w_{2}, h_{1_{i}}}{min} &amp; \quad -\gamma - \sum_{i}^{}x_{i}^\top w_{1}h_{1_{i}} \\
        s.t.                                            &amp; \qquad
        P \succeq 0                                                                                            \\
                                                        &amp; \qquad \gamma \gt 0
    \end{aligned}\]</span> where <span class="math inline">\( P:= \begin{bmatrix}
        \ast                 &amp; (1-\gamma)w_{1} &amp; \ast       &amp; \ast \\
        (1-\gamma)w_{1}^\top &amp; \ast            &amp; -\mathbb{I}    &amp; \ast \\
        \ast                 &amp; -\mathbb{I}         &amp; 2\mathbb{I}    &amp; w_2  \\
        \ast                 &amp; \ast            &amp; w_{2}^\top &amp; \ast \\
    \end{bmatrix} \)</span>.</p>
<h1 id="regularization">Regularization</h1>
<p>Regularizing the above problem to improve the structure of matrix. <span class="math display">\[\begin{aligned}
        \underset{w_1, w_2}{min} &amp; \tilde{J} = &amp; -x^\top  w_1 h_1 - \sigma(h_1)^\top  w_2 h_2 -\dfrac{\eta_{1}}{2}x^T x -\dfrac{\eta_{2}}{2}h_{1}^T h_{1} -\dfrac{\eta_{4}}{2}h_{2}^T h_{2}, ~~~~ \forall \eta_{1},~\eta_{2},~\eta_{4}\gt0
    \end{aligned}\]</span> and <span class="math inline">\( \eta_{3}\sigma\left(h_1 \right)^\top  \left( \sigma(h_1) - h_1 \right) \leq 0,~~~\forall h_1 , \eta_{3}\geq 0 \)</span>, we have the following optimization problem</p>
<p><span class="math display">\[\begin{aligned}
        \underset{\gamma, w_{1}, w_{2}, h_{1_{i}}}{min} &amp; \quad -\gamma - \sum_{i}^{}x_{i}^\top w_{1}h_{1_{i}} \\
        s.t.                                            &amp; \qquad
        \tilde{P} \succeq 0                                                                                    \\
                                                        &amp; \qquad \gamma \gt 0
    \end{aligned}\]</span></p>
<p>where <span class="math inline">\( \tilde{P}:= \begin{bmatrix}
        \eta_{1}             &amp; (1-\gamma)w_{1} &amp; \ast            &amp; \ast     \\
        (1-\gamma)w_{1}^\top &amp; \eta_{2}        &amp; -\eta_{3}\mathbb{I} &amp; \ast     \\
        \ast                 &amp; -\eta_{3}\mathbb{I} &amp; 2\eta_{3}\mathbb{I} &amp; w_2      \\
        \ast                 &amp; \ast            &amp; w_{2}^\top      &amp; \eta_{4} \\
    \end{bmatrix} \)</span>.</p>
<h2 id="from-bmi-to-lmi">From BMI to LMI</h2>
<p>Due to bilinearity in <span class="math inline">\( \tilde{P} \)</span>, the problem is in general NP-hard to solve. Hence a workaround is to impose a stronger condition on positive definiteness in the following way: <span class="math display">\[\tilde{P} = \tilde{P_{1}} + \tilde{P_{2}},\]</span> where <span class="math inline">\( \tilde{P_{1}} = \begin{bmatrix}
        \dfrac{\eta_{1}}{2} &amp; w_{1}               &amp; \ast            &amp; \ast     \\
        w_{1}^\top          &amp; \dfrac{\eta_{2}}{2} &amp; -\eta_{3}\mathbb{I} &amp; \ast     \\
        \ast                &amp; -\eta_{3}\mathbb{I}     &amp; 2\eta_{3}\mathbb{I} &amp; w_2      \\
        \ast                &amp; \ast                &amp; w_{2}^\top      &amp; \eta_{4} \\
    \end{bmatrix} \)</span> and <span class="math inline">\( \tilde{P_{2}} = \begin{bmatrix}
        \dfrac{\eta_{1}}{2} &amp; -\gamma w_{1}       &amp; \ast &amp; \ast \\
        -\gamma w_{1}^\top  &amp; \dfrac{\eta_{2}}{2} &amp; \ast &amp; \ast \\
        \ast                &amp; \ast                &amp; \ast &amp; \ast \\
        \ast                &amp; \ast                &amp; \ast &amp; \ast \\
    \end{bmatrix}. \)</span><br />
<br />
Left multiplying <span class="math inline">\( \tilde{P_{2}} \)</span> with <span class="math inline">\( \gamma^{-1} \)</span>, we get <span class="math inline">\( \tilde{P_{2}}^{&#39;} := \begin{bmatrix}
        \gamma^{-1}\dfrac{\eta_{1}}{2} &amp; - w_{1}                        &amp; \ast &amp; \ast \\
        - w_{1}^\top                   &amp; \gamma^{-1}\dfrac{\eta_{2}}{2} &amp; \ast &amp; \ast \\
        \ast                           &amp; \ast                           &amp; \ast &amp; \ast \\
        \ast                           &amp; \ast                           &amp; \ast &amp; \ast \\
    \end{bmatrix}.\)</span><br />
<br />
Hence, given <span class="math inline">\( \tilde{P_{1}} \succeq 0 \)</span> and <span class="math inline">\( \tilde{P_{2}} \succeq 0, \)</span> implies <span class="math inline">\( \tilde{P} \succeq 0\)</span>. Doing the change of variables <span class="math inline">\( L=w_{1}h_{1} \)</span>, to remove the bi-linearity from objective function and noting that <span class="math inline">\( {\left\lVertL\right\rVert}\leq{\left\lVertw_{1}\right\rVert} {\left\lVerth_{1}\right\rVert} \)</span> <span class="math inline">\( \leq {\left\lVertw_{1}\right\rVert} {\left\lVertx\right\rVert} \)</span>, since <span class="math inline">\( h_{1} \)</span> are just the latent variables of <span class="math inline">\( x \)</span>, we have the following reformulated problem</p>
<p><span class="math display">\[\label{eq: 2}
    \boxed{\begin{aligned}
            \underset{\gamma, w_{1}, w_{2}, L}{min} &amp; \quad -\gamma - Tr\left( x^\top L \right) \\
            s.t.                                    &amp; \qquad
            \tilde{P_{1}} \succeq 0                                                             \\
                                                    &amp; \qquad
            \tilde{P_{2}}^{&#39;} \succeq 0                                                         \\
                                                    &amp; \qquad \gamma \gt 0              \\
                                                    &amp; {\left\lVertL\right\rVert}\leq {\left\lVertw_{1}\right\rVert} {\left\lVertx\right\rVert}
        \end{aligned} }\]</span></p>
<p>Solving equation would yield <span class="math inline">\( \gamma,~  w_{1},~  w_{2}~ \&amp; ~ L \)</span>. Since <span class="math inline">\( w_{1} \in \mathbb{R}^{d\times s_{1}} \)</span> and <span class="math inline">\( h_{1} \in \mathbb{R}^{s_{1} \times N} \)</span>, we solve:</p>
<p><span class="math display">\[\begin{cases}
        Underdetermined ~system ~({\tiny no~ sol^{n}/infinitely~ many~ sol^{n}_{s}}),           &amp; \text{if } d\textless s_{1}    \\
        Overdetermined ~system~({\tiny mostly~ no ~sol^{n} ~except~ when~ lin.~ dep.~ exists}), &amp; \text{if } d\gt s_{1} \\
        Consistent ~system~(\tiny unique~ sol^{n} ~exists),                                     &amp; \text{if } d=s_{1}
    \end{cases}\]</span></p>
<p>Other than the consistent case, by choosing <span class="math inline">\( d\leq s_{1}  \)</span>, we prefer to solve the underdetermined system in the following way: <span class="math display">\[\begin{aligned}
        \underset{h_{1}}{min} &amp; \quad {\left\lVerth_{1}\right\rVert}^{2}_{2} \\
        s.t.                  &amp; \quad
        w_{1}h_{1}=L
    \end{aligned}\]</span> Solving the Lagrangian formulation and using KKT conditions we obtain</p>
<p><span class="math display">\[\label{}
    \boxed{h_{1}= w_{1}^{\top}\left( w_{1}w_{1}^{\top} \right)^{-1}L}\]</span></p>
<p>Now differentiating <span class="math inline">\( \tilde{J} \)</span> w.r.t <span class="math inline">\( h_{2} \)</span>, we obtain the solution for <span class="math inline">\( h_{2} \)</span> <span class="math display">\[\label{}
    \boxed{h_{2}=-\dfrac{1}{\eta_{4}}w_{2}^{\top}\sigma(h_{1})}\]</span></p>
</body>
</html>

        </div>
             
	
    	<span class="label label-default"><a href="/tags#distill-ref" title="View posts tagged with &quot;distill&quot;">distill</a></span>
    


     </article>
     <hr>
  


<ul class="pager">
  
      <li class="previous"><a href="/">&larr; Newer</a></li>
  
    
      <li class="next"><a href="/page3">Older &rarr;</a></li>
  
</ul>
</section>





</body>
</html>
